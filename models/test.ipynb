{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('./objects/perceptron.pkl')\n",
    "my_images = Path('../my_images')\n",
    "white = list(my_images.glob('White/*'))\n",
    "basmati = list(my_images.glob('Basmati/*'))\n",
    "jasmine = list(my_images.glob('Jasmine/*'))\n",
    "arborio = list(my_images.glob('Arborio/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White (1).jpg predicted as \t['Jasmine']\n",
      "White (2).jpg predicted as \t['Arborio']\n",
      "White (3).jpg predicted as \t['Arborio']\n",
      "White (4).jpg predicted as \t['Ipsala']\n",
      "White (5).jpg predicted as \t['Arborio']\n",
      "White (6).jpg predicted as \t['Basmati']\n",
      "White (7).jpg predicted as \t['Basmati']\n",
      "White (8).jpg predicted as \t['Ipsala']\n",
      "White (9).jpg predicted as \t['Basmati']\n",
      "White (10).jpg predicted as \t['Arborio']\n",
      "White (11).jpg predicted as \t['Karacadag']\n",
      "White (12).jpg predicted as \t['Jasmine']\n"
     ]
    }
   ],
   "source": [
    "for index, path in enumerate(white):\n",
    "    with PIL.Image.open(str(path)).convert('L') as img:\n",
    "        raw_image = np.array([np.array(img.getdata()).flatten()])\n",
    "        prediction = clf.predict(raw_image)\n",
    "        name = str(path).split('/')[-1]\n",
    "        print(f'{name} predicted as \\t{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is expected since I tested on some generic white rice and not a particular type of rice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 11968000 features, but SGDClassifier is expecting 62500 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mstr\u001b[39m(path))\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[1;32m      3\u001b[0m     raw_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39marray(img\u001b[38;5;241m.\u001b[39mgetdata())\u001b[38;5;241m.\u001b[39mflatten()])\n\u001b[0;32m----> 4\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m predicted as \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/repos/Rice Classifier/env/lib64/python3.13/site-packages/sklearn/linear_model/_base.py:374\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 374\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    376\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[0;32m~/repos/Rice Classifier/env/lib64/python3.13/site-packages/sklearn/linear_model/_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    349\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 351\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    354\u001b[0m     xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (scores\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[1;32m    357\u001b[0m )\n",
      "File \u001b[0;32m~/repos/Rice Classifier/env/lib64/python3.13/site-packages/sklearn/utils/validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/repos/Rice Classifier/env/lib64/python3.13/site-packages/sklearn/utils/validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2832\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 11968000 features, but SGDClassifier is expecting 62500 features as input."
     ]
    }
   ],
   "source": [
    "for index, path in enumerate(basmati):\n",
    "    with PIL.Image.open(str(path)).convert('L') as img:\n",
    "        raw_image = np.array([np.array(img.getdata()).flatten()])\n",
    "        prediction = clf.predict(raw_image)\n",
    "        name = str(path).split('/')[-1]\n",
    "        print(f'{name} predicted as \\t{prediction}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I can notice is that the model tends to predict shorter grains as Arborio and longer grains as Jasmine. It only predicts the last two images as Basmati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jasmine (1).jpg predicted as \t['Basmati']\n",
      "Jasmine (2).jpg predicted as \t['Basmati']\n",
      "Jasmine (3).jpg predicted as \t['Basmati']\n",
      "Jasmine (4).jpg predicted as \t['Jasmine']\n",
      "Jasmine (5).jpg predicted as \t['Jasmine']\n",
      "Jasmine (6).jpg predicted as \t['Jasmine']\n",
      "Jasmine (7).jpg predicted as \t['Basmati']\n",
      "Jasmine (8).jpg predicted as \t['Ipsala']\n",
      "Jasmine (9).jpg predicted as \t['Basmati']\n",
      "Jasmine (10).jpg predicted as \t['Basmati']\n",
      "Jasmine (11).jpg predicted as \t['Basmati']\n",
      "Jasmine (12).jpg predicted as \t['Basmati']\n",
      "Jasmine (13).jpg predicted as \t['Jasmine']\n",
      "Jasmine (14).jpg predicted as \t['Basmati']\n",
      "Jasmine (15).jpg predicted as \t['Basmati']\n",
      "Jasmine (16).jpg predicted as \t['Basmati']\n",
      "Jasmine (17).jpg predicted as \t['Basmati']\n",
      "Jasmine (18).jpg predicted as \t['Basmati']\n",
      "Jasmine (19).jpg predicted as \t['Jasmine']\n",
      "Jasmine (20).jpg predicted as \t['Basmati']\n",
      "Jasmine (21).jpg predicted as \t['Basmati']\n",
      "Jasmine (22).jpg predicted as \t['Basmati']\n",
      "Jasmine (23).jpg predicted as \t['Ipsala']\n",
      "Jasmine (24).jpg predicted as \t['Basmati']\n",
      "Jasmine (25).jpg predicted as \t['Basmati']\n",
      "Jasmine (26).jpg predicted as \t['Jasmine']\n",
      "Jasmine (27).jpg predicted as \t['Basmati']\n",
      "Jasmine (28).jpg predicted as \t['Jasmine']\n",
      "Jasmine (29).jpg predicted as \t['Basmati']\n"
     ]
    }
   ],
   "source": [
    "for index, path in enumerate(jasmine):\n",
    "    with PIL.Image.open(str(path)).convert('L') as img:\n",
    "        raw_image = np.array([np.array(img.getdata()).flatten()])\n",
    "        prediction = clf.predict(raw_image)\n",
    "        name = str(path).split('/')[-1]\n",
    "        print(f'{name} predicted as \\t{prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arborio (1).jpg predicted as \t['Jasmine']\n",
      "Arborio (2).jpg predicted as \t['Basmati']\n",
      "Arborio (3).jpg predicted as \t['Arborio']\n",
      "Arborio (4).jpg predicted as \t['Arborio']\n",
      "Arborio (5).jpg predicted as \t['Arborio']\n",
      "Arborio (6).jpg predicted as \t['Arborio']\n",
      "Arborio (7).jpg predicted as \t['Jasmine']\n",
      "Arborio (8).jpg predicted as \t['Arborio']\n",
      "Arborio (9).jpg predicted as \t['Arborio']\n",
      "Arborio (10).jpg predicted as \t['Ipsala']\n",
      "Arborio (11).jpg predicted as \t['Ipsala']\n",
      "Arborio (12).jpg predicted as \t['Basmati']\n",
      "Arborio (13).jpg predicted as \t['Arborio']\n",
      "Arborio (14).jpg predicted as \t['Arborio']\n",
      "Arborio (15).jpg predicted as \t['Basmati']\n",
      "Arborio (16).jpg predicted as \t['Arborio']\n",
      "Arborio (17).jpg predicted as \t['Jasmine']\n",
      "Arborio (18).jpg predicted as \t['Ipsala']\n",
      "Arborio (19).jpg predicted as \t['Ipsala']\n",
      "Arborio (20).jpg predicted as \t['Arborio']\n",
      "Arborio (21).jpg predicted as \t['Arborio']\n",
      "Arborio (22).jpg predicted as \t['Ipsala']\n",
      "Arborio (23).jpg predicted as \t['Arborio']\n",
      "Arborio (24).jpg predicted as \t['Ipsala']\n",
      "Arborio (25).jpg predicted as \t['Arborio']\n",
      "Arborio (26).jpg predicted as \t['Jasmine']\n",
      "Arborio (27).jpg predicted as \t['Ipsala']\n",
      "Arborio (28).jpg predicted as \t['Karacadag']\n",
      "Arborio (29).jpg predicted as \t['Ipsala']\n",
      "Arborio (30).jpg predicted as \t['Ipsala']\n",
      "Arborio (31).jpg predicted as \t['Basmati']\n",
      "Arborio (32).jpg predicted as \t['Ipsala']\n",
      "Arborio (33).jpg predicted as \t['Arborio']\n",
      "Arborio (34).jpg predicted as \t['Ipsala']\n",
      "Arborio (35).jpg predicted as \t['Arborio']\n",
      "Arborio (36).jpg predicted as \t['Arborio']\n",
      "Arborio (37).jpg predicted as \t['Basmati']\n",
      "Arborio (38).jpg predicted as \t['Ipsala']\n",
      "Arborio (39).jpg predicted as \t['Arborio']\n",
      "Arborio (40).jpg predicted as \t['Ipsala']\n",
      "Arborio (41).jpg predicted as \t['Ipsala']\n",
      "Arborio (42).jpg predicted as \t['Jasmine']\n",
      "Arborio (43).jpg predicted as \t['Ipsala']\n",
      "Arborio (44).jpg predicted as \t['Ipsala']\n",
      "Arborio (45).jpg predicted as \t['Arborio']\n",
      "Arborio (46).jpg predicted as \t['Arborio']\n",
      "Arborio (47).jpg predicted as \t['Arborio']\n"
     ]
    }
   ],
   "source": [
    "for index, path in enumerate(arborio):\n",
    "    with PIL.Image.open(str(path)).convert('L') as img:\n",
    "        raw_image = np.array([np.array(img.getdata()).flatten()])\n",
    "        prediction = clf.predict(raw_image)\n",
    "        name = str(path).split('/')[-1]\n",
    "        print(f'{name} predicted as \\t{prediction}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
